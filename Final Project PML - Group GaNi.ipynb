{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Laboratorium Machine Learning - Group GaNi\n",
    "#### Anggota Kelompok:\n",
    "1. Daniel Andrew Ketaren\t(211402062)\n",
    "2. Sarmida Uli Sinaga\t\t(211402071)\n",
    "3. Muhammad Hatta Abdillah\t(211402110)\n",
    "4. Luthfi Muzhaffar\tLubis\t(211402119)\n",
    "\n",
    "#### Dataset : Singapore Housing & Development Board (HBD) Resale Price \n",
    "Link :  https://drive.google.com/file/d/15Xwkyf5IkQiCoNP1xbLgNbOKwfNi2P73/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8417c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeac2e0",
   "metadata": {},
   "source": [
    "# A. Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ketentuan yang harus diikuti dalam melakukan filtering data di Dataset Singapore HDB Resale Price\n",
    "\n",
    "1. Data dari kedua dataset disatukan\n",
    "2. Data yang digunakan hanya dalam rentang 2016 - 2020, maka data selain rentang waktu 2015-2016 akan dihilangkan\n",
    "3. Memperbaiki format kolom yang salah\n",
    "4. Memperbaiki `missing values` dan `outlier` dengan cara cara yang tepat\n",
    "\n",
    "Maka, langkah langkah yang harus dilakukan agar `filtering` data ini berjalan dengan baik, antara lain:\n",
    "\n",
    "1. Melakukan penyatuan terhadap dua dataset yang diberikan sebelumnya, dengan tujuan agar kita dapat memanfaatkan kedua dataset dengan baik tanpa pemisahan\n",
    "2. Melakukan `filtering` data dengan ketentuan kita hanya akan memakai data dari tahun 2016-2020\n",
    "3. Melihat data setelah di`filter`\n",
    "4. Menentukan kolom yang memiliki format yang salah\n",
    "5. Mengubah kolom dengan format kolom yang salah itu tadi ke dalam format yang benar\n",
    "6. Melihat data setelah diformat\n",
    "7. Melihat `missing values` pada data\n",
    "8. Jikalau ada `missing values` pada data, maka akan diimplementasikan metode metode yang cocok diterapkan untuk menangani `missing values`-nya\n",
    "9. Melihat data setelah penanganan `missing values`\n",
    "10. Mengecek `sum`, `min`, `max` dari setiap kolom pada dataset yang dapat dikalkulasikan\n",
    "11. Melihat posibilitas data ada yang `outlier` atau tidak\n",
    "12. Melihat data yang `outlier`\n",
    "13. Menentukan apakah data yang `outlier` ini memanglah berdasar ataukah merupakan kesalahan dari inputan\n",
    "14. Mengimplementasikan kesimpulan dari poin ke 13\n",
    "15. Mengecek data yang duplikat\n",
    "16. Menghapus data yang duplikat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dari kedua dataset disatukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ebdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1 = '2015-to-2016.csv'\n",
    "csv2 = '2017-to-2020.csv'\n",
    "\n",
    "df1 = pd.read_csv(csv1)\n",
    "df2 = pd.read_csv(csv2)\n",
    "\n",
    "df_combined = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "csv_combined = '2016-to-2020.csv'\n",
    "df_combined.to_csv(csv_combined, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membaca data yang telah dicombine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e3b936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>174</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>255000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>541</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1981</td>\n",
       "      <td>65</td>\n",
       "      <td>275000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>163</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>69.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>64</td>\n",
       "      <td>285000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>446</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1979</td>\n",
       "      <td>63</td>\n",
       "      <td>290000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>557</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>64</td>\n",
       "      <td>290000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117522</th>\n",
       "      <td>2020-09</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>716</td>\n",
       "      <td>YISHUN ST 71</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>131.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1987</td>\n",
       "      <td>66 years 03 months</td>\n",
       "      <td>440000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117523</th>\n",
       "      <td>2020-09</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>760</td>\n",
       "      <td>YISHUN ST 72</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1987</td>\n",
       "      <td>65 years 06 months</td>\n",
       "      <td>458000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117524</th>\n",
       "      <td>2020-09</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>835</td>\n",
       "      <td>YISHUN ST 81</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1987</td>\n",
       "      <td>66 years 04 months</td>\n",
       "      <td>490000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117525</th>\n",
       "      <td>2020-09</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>EXECUTIVE</td>\n",
       "      <td>791</td>\n",
       "      <td>YISHUN AVE 2</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>146.0</td>\n",
       "      <td>Maisonette</td>\n",
       "      <td>1987</td>\n",
       "      <td>66 years 03 months</td>\n",
       "      <td>558000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117526</th>\n",
       "      <td>2020-09</td>\n",
       "      <td>YISHUN</td>\n",
       "      <td>EXECUTIVE</td>\n",
       "      <td>387</td>\n",
       "      <td>YISHUN RING RD</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>146.0</td>\n",
       "      <td>Maisonette</td>\n",
       "      <td>1988</td>\n",
       "      <td>66 years 09 months</td>\n",
       "      <td>555000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117527 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          month        town  flat_type block        street_name storey_range  \\\n",
       "0       2015-01  ANG MO KIO     3 ROOM   174   ANG MO KIO AVE 4     07 TO 09   \n",
       "1       2015-01  ANG MO KIO     3 ROOM   541  ANG MO KIO AVE 10     01 TO 03   \n",
       "2       2015-01  ANG MO KIO     3 ROOM   163   ANG MO KIO AVE 4     01 TO 03   \n",
       "3       2015-01  ANG MO KIO     3 ROOM   446  ANG MO KIO AVE 10     01 TO 03   \n",
       "4       2015-01  ANG MO KIO     3 ROOM   557  ANG MO KIO AVE 10     07 TO 09   \n",
       "...         ...         ...        ...   ...                ...          ...   \n",
       "117522  2020-09      YISHUN     5 ROOM   716       YISHUN ST 71     07 TO 09   \n",
       "117523  2020-09      YISHUN     5 ROOM   760       YISHUN ST 72     07 TO 09   \n",
       "117524  2020-09      YISHUN     5 ROOM   835       YISHUN ST 81     04 TO 06   \n",
       "117525  2020-09      YISHUN  EXECUTIVE   791       YISHUN AVE 2     04 TO 06   \n",
       "117526  2020-09      YISHUN  EXECUTIVE   387     YISHUN RING RD     04 TO 06   \n",
       "\n",
       "        floor_area_sqm      flat_model  lease_commence_date  \\\n",
       "0                 60.0        Improved                 1986   \n",
       "1                 68.0  New Generation                 1981   \n",
       "2                 69.0  New Generation                 1980   \n",
       "3                 68.0  New Generation                 1979   \n",
       "4                 68.0  New Generation                 1980   \n",
       "...                ...             ...                  ...   \n",
       "117522           131.0        Improved                 1987   \n",
       "117523           122.0        Improved                 1987   \n",
       "117524           122.0        Improved                 1987   \n",
       "117525           146.0      Maisonette                 1987   \n",
       "117526           146.0      Maisonette                 1988   \n",
       "\n",
       "           remaining_lease  resale_price  \n",
       "0                       70      255000.0  \n",
       "1                       65      275000.0  \n",
       "2                       64      285000.0  \n",
       "3                       63      290000.0  \n",
       "4                       64      290000.0  \n",
       "...                    ...           ...  \n",
       "117522  66 years 03 months      440000.0  \n",
       "117523  65 years 06 months      458000.0  \n",
       "117524  66 years 04 months      490000.0  \n",
       "117525  66 years 03 months      558000.0  \n",
       "117526  66 years 09 months      555000.0  \n",
       "\n",
       "[117527 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_combined)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memfilter data hanya 2016 sampai 2020 saja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed9b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penghapusan data\n",
    "tahun_target = ['2015']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    tahun = df['month'][i].split(\"-\", 1)[0]\n",
    "    \n",
    "    if tahun in tahun_target:\n",
    "        df = df.drop(i)\n",
    "\n",
    "# Menghapus indeks data 2015\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Kondisi data setelah data 2015 dihapus\n",
    "df.to_csv('2016-to-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat data yang sudah difilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503172ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_combine = '2016-to-2020.csv'\n",
    "\n",
    "df = pd.read_csv(csv_combine)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengecek data yang duplikat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengecek data duplikat ini berfungsi agar mengurangi ukuran dari dataset dan meningkatkan kinerja analisis data agar lebih akurat.\n",
    "\n",
    "Cara mengecek jumlah data yang duplikat adalah dengan memakai fungsi .duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat 246 data duplikat di dalam dataset ini, maka dari itu, kita akan melihat dulu, sebenaranya data apa saja yang duplikat tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mencari duplicated\n",
    "tes = df.duplicated()\n",
    "\n",
    "def filter_true_indices(series):\n",
    "    return series.index[series].tolist()\n",
    "\n",
    "# Menggunakan fungsi untuk mendapatkan indeks yang True\n",
    "true_indices = filter_true_indices(tes)\n",
    "\n",
    "df.iloc[true_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah benar benar yakin akan menghapus dataset tersebut, maka kita akan menghapus data diatas dengan menggunakan fungsi drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menentukan kolom yang memiliki format yang salah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perubahan pada remaining_lease agar data yang memiliki format yy years mm months berubah menjadi yy saja\n",
    "def transform_remaining_lease(lease):\n",
    "    if pd.notna(lease):\n",
    "        if lease.isdigit():\n",
    "            return int(lease)\n",
    "        elif 'year' in lease:\n",
    "            years = int(lease.split()[0])\n",
    "            return years\n",
    "        elif 'month' in lease:\n",
    "            years, months = map(int, lease.split()[:2])\n",
    "            if months <= 6:\n",
    "                return years\n",
    "            else:\n",
    "                return years + 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Mengganti nilai pada kolom remaining_lease dengan nilai yang baru\n",
    "df['remaining_lease'] = df['remaining_lease'].apply(transform_remaining_lease)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(df['remaining_lease'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat data setelah remaining_lease diubah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat missing values pada data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dikarenakan tidak ada missing values yang terlihat pada dataset, maka kita tidak perlu melakukan penanganan terhadap missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengecek sum, min, max, dan lain lain dari setiap kolom pada dataset yang dapat dikalkulasikan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat probabilitas data ada yang outlier atau tidak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['resale_price'], df['floor_area_sqm'])\n",
    "plt.title('Luas apartemen dengan harganya')\n",
    "plt.xlabel('Harga ')\n",
    "plt.ylabel('Luas apartemen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maka dapat dilihat bahwa ada sekitar 3 data yang sangat jauh dari kelompoknya, dan 3 data tersebut ada di kanan atas, yang memiliki arti harga yang mahal dan memiliki luas apartemen yang besar. Maka, yang harus dilakukan selanjutnya adalah melihat data yang diduga outliers tersebut, apakah outlier disebabkan kesalahan inputan atau memang ditetapkan harganya demikian.\n",
    "\n",
    "Kita akan melakukan pengecekan data yang outlier dengan menggunakan metode IQR (Interquartile Range) atau rentang akar kuartil dari sekumpulan data. IQR digunakan untuk membantu menarik kesimpulan tentang data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung nilai IQR pada floor_area_sqm\n",
    "Q1 = df['floor_area_sqm'].quantile(0.25) #kuartil 1\n",
    "Q3 = df['floor_area_sqm'].quantile(0.75) #kuartil 3\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print('Q1 = ', Q1)\n",
    "print('Q3 = ', Q3)\n",
    "print('IQR wheel base = ', IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memeriksa outlier seluruh kolom yang bertipekan int64 dan float64\n",
    "for i in (df.columns):\n",
    "    if(df[i].dtypes in ['int64', 'float64']):\n",
    "        print(i, ' : ', df[i].dtypes)\n",
    "\n",
    "        Q1 = df[i].quantile(0.25) #kuartil 1\n",
    "        print('Q1 = ', Q1)\n",
    "\n",
    "        Q3 = df[i].quantile(0.75) #kuartil 3\n",
    "        print('Q3 = ', Q3)\n",
    "\n",
    "        IQR = Q3 - Q1\n",
    "        print('IQR wheel base = ', IQR)\n",
    "\n",
    "        nilai_minimum = df[i].min()\n",
    "        nilai_maximum = df[i].max()\n",
    "\n",
    "        minimum_IQR = Q1 - 3.5 * IQR\n",
    "        maximum_IQR = Q3 + 3.5 * IQR\n",
    "\n",
    "        if(nilai_minimum < minimum_IQR):\n",
    "            print('Low outlier ditemukan <', minimum_IQR)\n",
    "            print('Indeks dari low outlier : ', list(df[df[i] < minimum_IQR].index)) # indeks low outlier\n",
    "\n",
    "        if(nilai_maximum > maximum_IQR):\n",
    "            print('High outlier ditemukan >', maximum_IQR)\n",
    "            print('Indeks dari high outlier : ', list(df[df[i] > maximum_IQR].index)) # indeks high outlier\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maka dapat dilihat bahwa memang hanya resale_price dan floor_area_sqm sajalah yang memiliki outlier, dimana:\n",
    "\n",
    "1. floor_area_sqm hanya memiliki high outlier, dan\n",
    "2. resale_price hanya memiliki high outlier\n",
    "\n",
    "Kemudian, kita akan melihat data yang outlier dari masing masing kolom yang memiliki outlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melihat data high outlier pada kolom floor_area_sqm\n",
    "df.iloc[[18710, 39066, 55149]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari data yang ada diatas, kami menyimpulkan bahwa sebenarnya data floor_area_sqm yang tergolong high outlier bukan disebabkan oleh kesalahan inputan, namun memang adalah luas permeter yang sesuai dengan kondisi apartemen terrace pada umumnya. Maka tidak ada alasan untuk menghapus data tersebut.\n",
    "\n",
    "Seperti yang diketahui, apatemen model terrace memang cenderung lebih luas dibandingkan apartemen model lain, hal ini disebabkan karena apartemen model ini memiliki halaman depan untuk bersantai seperti di rumah, sehingga semakin memperluas ukuran lantai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melihat data high outlier pada kolom resale_price\n",
    "df.iloc[[18710, 20702, 30227, 42616, 43102, 51200, 53879, 55149, 56633, 60304, 61219, 61816, 62223, 62720, 64497, 66332, 69160, 70382, 72887, 73137, 74371, 87678, 90515, 91489, 95378, 97851, 97853, 98838]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidak menghapus data tersebut juga didasari pada sebagian besar data yang diduga outlier pada kolom resale_price tersebut termasuk dalam golongan yang memiliki ruangan yang banyak, didominasi oleh 5 room, dan sebagian lainnya termasuk pada tipe eksekutif. Maka tidak heran jikalau harganya tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kesimpulan dari mencari probabilitas data outlier ini adalah bahwa data data yang ditemukan terindikasi outlier ternyata bukanlah merupakan data yang mengalami kesalahan penulisan, melainkan adalah data sebenarnya dan masih terlihat masuk akal untuk nilainya, hal itu yang membuat kami tidak memiliki niatan yang mendesak untuk menghapus data data yang terindikasi outlier tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapun insights yang dapat diambil meliputi: \n",
    "1. Analisis lokasi properti di Singapura untuk menentukan nilai yang sepadan.\n",
    "2. Identifikasi faktor-faktor penentu harga properti yang paling signifikan.\n",
    "3. Eksplorasi tren dan volume transaksi properti dari tahun 2016 hingga 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Analisis lokasi properti di Singapura untuk menentukan nilai yang sepadan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapun ketentuan daerah yang paling sepadan disini merujuk dari indikator:\n",
    "\n",
    "1. Mahal atau tidaknya suatu apartemen di `daerah` tersebut\n",
    "2. `Luas` atau tidaknya bangunan tersebut\n",
    "3. Berapa harga rata rata dari bangunan berdasarkan `flat_typenya`\n",
    "4. Berapa harga rata rata dari bangunan berdasarkan `flat_modelnya`\n",
    "\n",
    "Maka, pertama tama, kita akan melihat dulu kolom mana saja yang cocok untuk dijadikan indikator untuk menentukan daerah mana saja yang paling sepadan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melihat data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari data di atas, kita bisa memakai beberapa kolom antara lain:\n",
    "\n",
    "2. `Flat type` untuk menentukan seberapa pengaruh flat_type terhadap harga jual kembali\n",
    "3. `Town` sebagai nama kota\n",
    "4. `Floor_area_sqm` sebagai indikator luas apartemennya\n",
    "5. `Flat_model` sebagai penanda apartemen tersebut bagaimana modelnya\n",
    "6. `resale_price` sebagai harga dari apartemen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melihat persebaran harga apartemen berdasarkan harga resale_price dan luasnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat bins untuk resale_price\n",
    "bins = pd.cut(df['resale_price'], bins=range(0, 1400000, 200000), right=False)\n",
    "\n",
    "# Membuat tabel silang dengan pd.crosstab\n",
    "data = pd.crosstab(df['town'], bins)\n",
    "plt.figure(figsize=(8, 6))                                                                  # Ubah nilai tinggi gambar sesuai kebutuhan Anda\n",
    "sns.heatmap(data,cmap='Reds',annot=True, fmt='g', linewidths=.5)\n",
    "plt.title(\"Heatmap kota dengan persebaran banyak apartemen dengan rentang resale_price\\n\")\n",
    "plt.show()\n",
    "\n",
    "# Membuat bins untuk floor_area_sqm\n",
    "bins2 = pd.cut(df['floor_area_sqm'], bins=range(0, 260, 50), right=False)\n",
    "\n",
    "# Membuat tabel silang dengan pd.crosstab\n",
    "data2 = pd.crosstab(df['town'], bins2)\n",
    "plt.figure(figsize=(8, 6))                                                                  # Ubah nilai tinggi gambar sesuai kebutuhan Anda\n",
    "sns.heatmap(data2,cmap='Reds',annot=True, fmt='g', linewidths=.5)\n",
    "plt.title(\"Heatmap kota dengan persebaran banyak apartemen dengan rentang floor_area_sqm\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat dari tabel ke 1, terdapat beberapa kesimpulan yang dapat diambil, antara lain:\n",
    "\n",
    "1. Untuk apartemen dengan rentang harga resale_price dibawah 200000, cenderung sedikit dan sulit untuk ditemukan\n",
    "\n",
    "2. Daerah Woodlands dan Yishun terdapat banyak sekali apartemen yang cukup murah dengan kisaran harga 200000 sampai 400000\n",
    "\n",
    "3. Daerah Sengkang menempati urutan pertama sebagai daerah dengan jumlah apartemen berharga sedang terbanyak diantara daerah lain, dengan rentang harga 400000 sampai 600000\n",
    "\n",
    "4. Bukit Merah merupakan daerah yang didominasi oleh apartemen berharga menengah ke atas.\n",
    "\n",
    "\n",
    "Kemudian dilihat dari tabel ke 2, terdapat beberapa kesimpulan yang dapat diambil, antara lain:\n",
    "\n",
    "1. Untuk apartemen ukuran kurang dari 50 sqm ada, namun tidak cukup banyak pilihan di hampir seluruh daerah, kecuali Bukit Merah dan Sengkang, itupun tetap dikategorikan rendah walau agak signifikan\n",
    "\n",
    "2. Untuk apartemen berukuran antara 50-100 sqm, pilihan terbanyak terdapat di 5 daerah, yaitu Yishun (terbanyak), Sengkang, Punggol, Bedok, dan Ang Mo Kio\n",
    "\n",
    "3. Untuk apartemen berukuran sedang (100-150 sqm), pilihan terbanyak terdapat di 3 daerah, yaitu Woodlands, Yishun, dan Jurong West\n",
    "\n",
    "4. Adapula Woodlands juga mendominasi apartemen besar dengan ukuran antara 150-200 sqm\n",
    "\n",
    "5. Untuk apartemen ukuran raksasa (200-250 sqm), tidak banyak dan tidak bisa didapati di semua daerah, hanya terdapat di Kallang dan Choa Chu Kang\n",
    "\n",
    "Maka dapat disimpulkan :\n",
    "\n",
    "Apabila pelanggan menginginkan apartemen yang murah, maka Woodlands dan Yishun adalah pilihan tepat, begitu juga dengan ketersediaan apartemen yang standar, Woodlands dan Yishun juga mendominasi. Maka Woodlands dan Yishun adalah daerah yang paling worth-it jikalau didasarkan pada harga dan luas area apartemen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Identifikasi faktor-faktor penentu harga properti yang paling signifikan\n",
    "\n",
    "Harga properti yang ada pada kolom `resale_price`, dapat divisualisasikan dengan kolom kolom lain untuk melihat keterkaitan antara kolom kolom tersebut dengan `resale_price`. Hal ini juga dapat membantu menemukan model yang tepat kedepannya.\n",
    "\n",
    "Kolom kolom yang akan dicek antara lain pengaruhnya antara lain:\n",
    "\n",
    "1. `flat_type` terhadap `resale_price`\n",
    "2. `floor_area` terhadap `resale_price`\n",
    "3. `flat_model` terhadap `resale_price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pengaruh flat_type terhadap resale_price\n",
    "\n",
    "Kali ini kita akan melihat bagaimana pengaruh dari Tipe Flat terhadap harga jual kembali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan urutan kategori flat_type\n",
    "flat_type_order = df.flat_type.unique()\n",
    "\n",
    "# Menghitung rata-rata resale_price_per_sqm untuk setiap flat_type dan kota\n",
    "average_price_per_flat_type = df.groupby(['town', 'flat_type'])['resale_price'].min().reset_index()\n",
    "\n",
    "# Filter hanya flat_type yang ada dalam urutan yang telah ditentukan\n",
    "average_price_per_flat_type = average_price_per_flat_type[average_price_per_flat_type['flat_type'].isin(flat_type_order)]\n",
    "\n",
    "# Membuat cross-tabulation untuk heatmap dengan rata-rata\n",
    "data_collab = pd.crosstab(average_price_per_flat_type['town'], average_price_per_flat_type['flat_type'], values=average_price_per_flat_type['resale_price'], aggfunc='mean')\n",
    "\n",
    "# Membuat heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data_collab, cmap='Reds', annot=True, fmt='.2f', linewidths=.5, annot_kws={'size': 8})\n",
    "plt.title(\"Heatmap kota dengan rata-rata harga resale_price (berdasarkan flat_type)\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari sini dapat kita lihat, bahwa semakin besar jumlah ruangan, maka harga jual apartemen semakin tinggi, kemudian untuk tipe eksekutif dan multi generation, adalah tipe yang lebih tinggi nilai jualnya dibanding 1-5 ROOM.\n",
    "\n",
    "Kesimpulannya adalah, tipe flat dapat mempengaruhi harga jual pada apartemen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pengaruh floor_area terhadap resale_price\n",
    "\n",
    "Kali ini kita akan melihat bagaimana pengaruh dari Luas Apartemen terhadap harga jual kembali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan urutan kategori flat_type\n",
    "floor_area_sqm_order = pd.cut(df['floor_area_sqm'], bins=range(0, 250, 40), right=False)\n",
    "\n",
    "# Menghitung rata-rata resale_price_per_sqm untuk setiap flat_type dan kota\n",
    "average_price_per_floor_area_sqm = df.groupby(['town', floor_area_sqm_order])['resale_price'].mean().reset_index()\n",
    "\n",
    "# Membuat cross-tabulation untuk heatmap dengan rata-rata\n",
    "data_collab = pd.crosstab(average_price_per_floor_area_sqm['town'], average_price_per_floor_area_sqm['floor_area_sqm'], values=average_price_per_floor_area_sqm['resale_price'], aggfunc='mean')\n",
    "\n",
    "# Membuat heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data_collab, cmap='Reds', annot=True, fmt='.2f', linewidths=.5, annot_kws={'size': 8})\n",
    "plt.title(\"Heatmap kota dengan rata-rata luas bangunan (berdasarkan flat_type)\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari sini dapat kita lihat, bahwa semakin luas apartemen, maka harga jual apartemen semakin tinggi.\n",
    "\n",
    "Kesimpulannya adalah, floor_area_sqm juga dapat mempengaruhi harga jual pada apartemen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pengaruh flat_model terhadap resale_price\n",
    "\n",
    "Kali ini kita akan melihat bagaimana pengaruh dari Model Flat terhadap harga jual kembali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan urutan kategori flat_type\n",
    "flat_model_order = df.flat_model.unique()\n",
    "\n",
    "# Menghitung rata-rata resale_price_per_sqm untuk setiap flat_type dan kota\n",
    "average_price_per_flat_model = df.groupby(['town', 'flat_model'])['floor_area_sqm'].min().reset_index()\n",
    "\n",
    "# Filter hanya flat_type yang ada dalam urutan yang telah ditentukan\n",
    "average_price_per_flat_model = average_price_per_flat_model[average_price_per_flat_model['flat_model'].isin(flat_model_order)]\n",
    "\n",
    "# Membuat cross-tabulation untuk heatmap dengan rata-rata\n",
    "data_collab = pd.crosstab(average_price_per_flat_model['town'], average_price_per_flat_model['flat_model'], values=average_price_per_flat_model['floor_area_sqm'], aggfunc='mean')\n",
    "\n",
    "# Membuat heatmap\n",
    "plt.figure(figsize=(13, 6))\n",
    "sns.heatmap(data_collab, cmap='Reds', annot=True, fmt='.2f', linewidths=.5, annot_kws={'size': 8})\n",
    "plt.title(\"Heatmap kota dengan rata-rata luas bangunan (berdasarkan flat_model)\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari sini dapat kita lihat, bahwa setiap model flat memiliki tingkat merahnya sendiri sendiri dan berbeda antara satu flat model dengan flat model lainnya.\n",
    "\n",
    "Kesimpulannya adalah, flat_model juga dapat mempengaruhi harga jual pada apartemen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Eksplorasi tren dan volume transaksi properti dari tahun 2016 hingga 2020.\n",
    "\n",
    "Harga properti yang ada pada kolom `resale_price`, dapat divisualisasikan dengan kolom kolom lain untuk melihat keterkaitan antara kolom kolom tersebut dengan resale_price. Hal ini juga dapat membantu menemukan model yang tepat kedepannya.\n",
    "\n",
    "Kolom kolom yang akan dicek antara lain pengaruhnya antara lain:\n",
    "\n",
    "1. flat_type terhadap resale_price\n",
    "2. floor_area terhadap resale_price\n",
    "3. flat_model terhadap resale_price\n",
    "\n",
    "Sebelum itu, kita akan membaca terlebih dahulu datanya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapan data\n",
    "df['datetime'] = pd.to_datetime(df['month'])\n",
    "df['year'] = df['datetime'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pergolakan tren harga jual kembali dari tahun 2016 hingga 2020\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='year', y='resale_price', data = df)\n",
    "plt.title('Tren Harga Jual Kembali Properti (2016-2020)')\n",
    "plt.xlabel('Tahun')\n",
    "plt.ylabel('Harga Jual Kembali')\n",
    "plt.show()\n",
    "\n",
    "average_price_per_year = df.groupby('month')['resale_price'].mean()\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.plot(average_price_per_year.index, average_price_per_year.values, marker='o')\n",
    "plt.title('Tren Rata-rata Harga Jual Properti per Tahun')\n",
    "plt.xlabel('Tahun')\n",
    "plt.ylabel('Rata-rata Harga Jual')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()\n",
    "\n",
    "# Volume transaksi properti dari tahun 2016 hingga 2020\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='year', data = df)\n",
    "plt.title('Volume Transaksi Properti (2016-2020)')\n",
    "plt.xlabel('Tahun')\n",
    "plt.ylabel('Jumlah Transaksi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Pembuatan Model (Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kali ini, kita akan membuat sebuah model dimana kolom yang akan diprediksi adalah resale_price, adapun kolom kolom lain yang akan diikutkan pada model antara lain:\n",
    "\n",
    "1. town (hal ini didasarkan pada ada sebagian kota di daerah Singapura yang harga apartemennya cenderung lebih mahal (ditandai dengan merah pekat) daripada daerah daerah lainnya, hal ini memungkinkan relasi antara dimana letak apartemennya dan harganya (meskipun tidak semua daerah berlaku hal seperti ini))\n",
    "\n",
    "2. flat_type (hal ini didasarkan pada visualisasi sebelumnya yang mana antara flat_type satu dan yang lainnya menunjukkan perbedaan kepekatan warna, dimana hal itu berarti ada pengaruh dari flat_type terhadap harga jual kembali)\n",
    "\n",
    "3. floor_area_sqm (hal ini didasarkan pada visualisasi sebelumnya yang mana semakin tinggi nilai floor_area_sqm, maka semakin mahal pulalah harga jual kembalinya)\n",
    "\n",
    "4. flat_model (hal ini didasarkan pada visualisasi sebelumnya yang mana antara flat_model yang satu dengan yang lainnya menunjukkan perbedaan kepekatan warna, dimana hal itu berarti ada pengaruh flat_model terhadap harga jual kembali)\n",
    "\n",
    "Maka oleh karena itu, mari kita melihat terlebih dahulu tabel nya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat, bahwa kolom town, flat_type, dan flat_model masih berbentuk object, dan hanya floor_area_sqm saja yang sudah berbentuk float. Oleh karena itu, kita akan melaksanakan one hot encoding sebagai langkah untuk mengkategorisasi setiap object tersebut ke dalam kolom kolom yang berisikan nilai numerik 0 dan 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk town\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohetransform_city = ohe.fit_transform(df['town'].values.reshape(-1, 1))\n",
    "ohetransform_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penyatuan one hot encoding pada town ke df\n",
    "\n",
    "df = pd.concat([df, ohetransform_city], axis=1).drop(columns = ['town'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk flat type\n",
    "\n",
    "ohetransform_flat_type = ohe.fit_transform(df['flat_type'].values.reshape(-1, 1))\n",
    "ohetransform_flat_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penyatuan one hot encoding pada town ke df\n",
    "\n",
    "df = pd.concat([df, ohetransform_flat_type], axis=1).drop(columns = ['flat_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk flat model\n",
    "ohetransform_flat_model = ohe.fit_transform(df['flat_model'].values.reshape(-1, 1))\n",
    "ohetransform_flat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, ohetransform_flat_model], axis=1).drop(columns = ['flat_model'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melakukan one hot encoding terhadap ketiga kolom tersebut, selanjutnya yang kita lakukan adalah mendrop tabel yang tidak diperlukan dalam permodelan, kolom kolom itu antara lain:\n",
    "\n",
    "1. month\n",
    "2. block\n",
    "3. street_name\n",
    "4. storey_range\n",
    "5. datetime\n",
    "6. year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = ['month', 'block', 'street_name', 'storey_range', 'datetime', 'year']\n",
    "\n",
    "df = df.drop(labels=col_drop, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"resale_price\"], axis=1)\n",
    "y = df[\"resale_price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "model_xgb = XGBRegressor()\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "model_xgb = XGBRegressor()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Ridge Regression\n",
    "alpha_ridge = 1.0  # You can adjust the alpha for Ridge Regression\n",
    "model_ridge = Ridge(alpha=alpha_ridge)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Lasso Regression\n",
    "alpha_lasso = 1.0  # You can adjust the alpha for Lasso Regression\n",
    "model_lasso = Lasso(alpha=alpha_lasso)\n",
    "model_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linear = model_linear.predict(X_test)\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "\n",
    "y_pred_ridge = model_ridge.predict(X_test)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mse_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"MAE_Linear: \", mae_linear)\n",
    "print (\"MSE_Linear: \", mse_linear)\n",
    "print (\"MAE_Linear: \", rmse_linear)\n",
    "print(\"\\r\")\n",
    "print (\"MAE_rf: \", mae_rf)\n",
    "print (\"MSE_rf: \", mse_rf)\n",
    "print (\"RMSE_rf: \", rmse_rf)\n",
    "print(\"\\r\")\n",
    "print (\"MAE_xgb: \", mae_xgb)\n",
    "print (\"MSE_xgb: \", mse_xgb)\n",
    "print (\"RMSE_xgb: \", rmse_xgb)\n",
    "print(\"\\r\")\n",
    "print (\"MAE_ridge: \", mae_ridge)\n",
    "print (\"MSE_ridge: \", mse_ridge)\n",
    "print (\"RMSE_ridge: \", rmse_ridge)\n",
    "print(\"\\r\")\n",
    "print (\"MAE_lasso: \", mae_lasso)\n",
    "print (\"MSE_lasso: \", mse_lasso)\n",
    "print (\"RMSE_lasso: \", rmse_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maka dilihat dari sini dapat disimpulkan bahwa model Rain Forest adalah yang paling cocok untuk permodelan pada dataset ini, maka kita akan lanjut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_linear.coef_)\n",
    "print(model_linear.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
